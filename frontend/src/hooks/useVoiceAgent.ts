import { useState, useRef, useCallback, useEffect } from 'react';
import { useQuery } from '@tanstack/react-query';
import { RealtimeAgent, RealtimeSession, OpenAIRealtimeWebRTC } from '@openai/agents/realtime';
import { configApi } from '@/services/config';
import { personalityApi } from '@/services/personality';
import type { OpenAIConfig } from '@/services/config';

/**
 * Voice Agent Hookè¿”å›å€¼
 */
export interface UseVoiceAgentReturn {
  /** æ˜¯å¦å·²è¿æ¥ */
  isConnected: boolean;
  /** æ˜¯å¦æ­£åœ¨é€šè¯ */
  isCalling: boolean;
  /** é”™è¯¯ä¿¡æ¯ */
  error: string | null;
  /** ç”¨æˆ·éŸ³é¢‘é¢‘ç‡æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ */
  userFrequencyData: Uint8Array | null;
  /** åŠ©æ‰‹éŸ³é¢‘é¢‘ç‡æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ */
  assistantFrequencyData: Uint8Array | null;
  /** è¿æ¥ Voice Agent */
  connect: () => Promise<void>;
  /** æ–­å¼€è¿æ¥ */
  disconnect: () => void;
  /** å¼€å§‹é€šè¯ */
  startCall: () => Promise<void>;
  /** ç»“æŸé€šè¯ */
  endCall: () => Promise<void>;
}

/**
 * Voice Agent Hook
 *
 * ä½¿ç”¨ OpenAI Agents SDK çš„ Realtime API å®ç°è¯­éŸ³é€šè¯åŠŸèƒ½ã€‚
 * ç”±äº oneapi.naivehero.top æ˜¯ api.openai.com çš„å®Œæ•´é•œåƒï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ OpenAI SDKã€‚
 *
 * @param sessionId - ä¼šè¯ID
 * @param personalityId - äººæ ¼ID
 * @param callbacks - å›è°ƒå‡½æ•°
 * @returns Voice Agent Hookè¿”å›å€¼
 */
export const useVoiceAgent = (
  _sessionId?: string,
  personalityId?: string,
  callbacks?: {
    onUserTranscript?: (text: string) => void;
    onAssistantTranscript?: (text: string) => void;
  }
): UseVoiceAgentReturn => {
  const [isConnected, setIsConnected] = useState(false);
  const [isCalling, setIsCalling] = useState(false);
  const [error, setError] = useState<string | null>(null);
  
  const sessionRef = useRef<RealtimeSession | null>(null);
  const configRef = useRef<OpenAIConfig | null>(null);
  const isCallingRef = useRef(false);
  
  // éŸ³é¢‘æµå’Œå…ƒç´ å¼•ç”¨ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
  const userMediaStreamRef = useRef<MediaStream | null>(null);
  const assistantAudioElementRef = useRef<HTMLAudioElement | null>(null);
  
  // éŸ³é¢‘å¯è§†åŒ–ç›¸å…³
  const userAnalyserRef = useRef<AnalyserNode | null>(null);
  const assistantAnalyserRef = useRef<AnalyserNode | null>(null);
  const assistantSourceRef = useRef<MediaElementAudioSourceNode | null>(null);
  const assistantAudioContextRef = useRef<AudioContext | null>(null);
  const [userFrequencyData, setUserFrequencyData] = useState<Uint8Array | null>(null);
  const [assistantFrequencyData, setAssistantFrequencyData] = useState<Uint8Array | null>(null);
  const userAnimationFrameRef = useRef<number | null>(null);
  const assistantAnimationFrameRef = useRef<number | null>(null);
  
  // è·å– personality é…ç½®
  const { data: personality } = useQuery({
    queryKey: ['personality', personalityId],
    queryFn: () => personalityApi.getPersonality(personalityId!),
    enabled: !!personalityId,
  });

  /**
   * åŠ è½½é…ç½®
   */
  const loadConfig = useCallback(async (): Promise<OpenAIConfig> => {
    if (configRef.current) {
      return configRef.current;
    }
    
    const config = await configApi.getOpenAIConfig();
    configRef.current = config;
    return config;
  }, []);

  /**
   * åˆå§‹åŒ–ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–
   */
  const initUserAudioVisualization = useCallback(async (stream: MediaStream) => {
    try {
      console.log('å¼€å§‹åˆå§‹åŒ–ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–ï¼Œstream:', stream, 'tracks:', stream.getTracks().length);
      
      // æ£€æŸ¥ AudioContext çŠ¶æ€
      let audioContext: AudioContext;
      try {
        audioContext = new AudioContext({ sampleRate: 24000 });
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
          console.log('AudioContext å·²æ¢å¤');
        }
      } catch (e) {
        console.error('åˆ›å»º AudioContext å¤±è´¥:', e);
        return;
      }
      
      const source = audioContext.createMediaStreamSource(stream);
      
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256; // å¢åŠ  fftSize ä»¥è·å¾—æ›´å¥½çš„é¢‘ç‡åˆ†è¾¨ç‡
      analyser.smoothingTimeConstant = 0.3; // é™ä½å¹³æ»‘åº¦ï¼Œæé«˜å“åº”é€Ÿåº¦
      userAnalyserRef.current = analyser;
      
      source.connect(analyser);
      console.log('ç”¨æˆ·éŸ³é¢‘æºå·²è¿æ¥åˆ°åˆ†æå™¨');
      
      // å¯åŠ¨ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–ï¼ˆä½¿ç”¨ requestAnimationFrame æé«˜å“åº”é€Ÿåº¦ï¼‰
      const updateUserAudioVisualization = () => {
        if (!userAnalyserRef.current) {
          console.log('ç”¨æˆ·åˆ†æå™¨ä¸å­˜åœ¨ï¼Œåœæ­¢æ›´æ–°');
          return;
        }
        
        // æ£€æŸ¥ isCalling çŠ¶æ€ï¼ˆä½¿ç”¨ ref è€Œä¸æ˜¯é—­åŒ…ä¸­çš„å€¼ï¼‰
        if (!isCallingRef.current) {
          console.log('ä¸åœ¨é€šè¯ä¸­ï¼Œåœæ­¢ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–');
          return;
        }
        
        try {
          const bufferLength = userAnalyserRef.current.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);
          userAnalyserRef.current.getByteFrequencyData(dataArray);
          
          setUserFrequencyData(dataArray);
          
          // ä½¿ç”¨ requestAnimationFrame æé«˜å“åº”é€Ÿåº¦ï¼ˆçº¦ 60fpsï¼‰
          userAnimationFrameRef.current = requestAnimationFrame(() => {
            updateUserAudioVisualization();
          }) as any;
        } catch (err) {
          console.error('æ›´æ–°ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–å¤±è´¥:', err);
        }
      };
      
      // å»¶è¿Ÿå¯åŠ¨ï¼Œç¡®ä¿ isCallingRef å·²è®¾ç½®
      setTimeout(() => {
        updateUserAudioVisualization();
      }, 200);
    } catch (err: any) {
      console.error('åˆå§‹åŒ–ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–å¤±è´¥:', err);
    }
  }, []);

  /**
   * åˆå§‹åŒ–åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–
   */
  const initAssistantAudioVisualization = useCallback((audioElement: HTMLAudioElement) => {
    try {
      console.log('å¼€å§‹åˆå§‹åŒ–åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–ï¼ŒaudioElement:', audioElement, 'srcObject:', audioElement.srcObject);
      
      // æ¸…ç†ä¹‹å‰çš„è¿æ¥ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
      if (assistantSourceRef.current) {
        try {
          assistantSourceRef.current.disconnect();
        } catch (e) {
          // å¿½ç•¥æ–­å¼€è¿æ¥é”™è¯¯
        }
        assistantSourceRef.current = null;
      }
      
      if (assistantAudioContextRef.current) {
        try {
          assistantAudioContextRef.current.close();
        } catch (e) {
          // å¿½ç•¥å…³é—­é”™è¯¯
        }
        assistantAudioContextRef.current = null;
      }
      
      // æ£€æŸ¥ AudioContext çŠ¶æ€
      let audioContext: AudioContext;
      try {
        audioContext = new AudioContext({ sampleRate: 24000 });
        assistantAudioContextRef.current = audioContext;
        if (audioContext.state === 'suspended') {
          audioContext.resume().then(() => {
            console.log('åŠ©æ‰‹ AudioContext å·²æ¢å¤');
          });
        }
      } catch (e) {
        console.error('åˆ›å»ºåŠ©æ‰‹ AudioContext å¤±è´¥:', e);
        return;
      }
      
      // ä¼˜å…ˆä½¿ç”¨ srcObject çš„ MediaStreamï¼ˆæ›´å¯é ï¼Œä¸ä¼šå‡ºç°"already connected"é”™è¯¯ï¼‰
      // æ³¨æ„ï¼šä¸è¦åŒæ—¶ä½¿ç”¨ MediaStreamSource å’Œ MediaElementSourceï¼Œä¼šå¯¼è‡´é‡å¤æ’­æ”¾
      let source: MediaElementAudioSourceNode | MediaStreamAudioSourceNode;
      
      if (audioElement.srcObject instanceof MediaStream) {
        // å¦‚æœ audioElement æœ‰ srcObjectï¼ˆMediaStreamï¼‰ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
        console.log('âœ… ä½¿ç”¨ audioElement.srcObject (MediaStream) åˆ›å»ºéŸ³é¢‘æº', {
          streamId: audioElement.srcObject.id,
          tracks: audioElement.srcObject.getTracks().length,
          active: audioElement.srcObject.active,
        });
        try {
          const streamSource = audioContext.createMediaStreamSource(audioElement.srcObject);
          assistantSourceRef.current = streamSource as any;
          source = streamSource;
        } catch (e: any) {
          console.error('âŒ ä» MediaStream åˆ›å»ºéŸ³é¢‘æºå¤±è´¥:', e);
          throw e;
        }
      } else {
        // å¦‚æœæ²¡æœ‰ srcObjectï¼Œå°è¯•ä» audioElement åˆ›å»º MediaElementSource
        // ä½†è¦æ³¨æ„ï¼šå¦‚æœ audioElement å·²ç»è¢«è¿æ¥è¿‡ï¼Œä¼šæŠ¥é”™
        console.log('âš ï¸ audioElement æ²¡æœ‰ srcObjectï¼Œå°è¯•åˆ›å»º MediaElementSource');
        try {
          source = audioContext.createMediaElementSource(audioElement);
          assistantSourceRef.current = source;
        } catch (e: any) {
          if (e.name === 'InvalidStateError' && e.message.includes('already connected')) {
            console.warn('âš ï¸ éŸ³é¢‘å…ƒç´ å·²è¢«è¿æ¥ï¼Œè·³è¿‡å¯è§†åŒ–ï¼ˆé¿å…é‡å¤æ’­æ”¾ï¼‰');
            // ä¸æŠ›å‡ºé”™è¯¯ï¼Œåªæ˜¯è·³è¿‡å¯è§†åŒ–
            return;
          } else {
            throw e;
          }
        }
      }
      
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 512; // å¢åŠ  fftSize ä»¥è·å¾—æ›´å¥½çš„é¢‘ç‡åˆ†è¾¨ç‡
      analyser.smoothingTimeConstant = 0.1; // è¿›ä¸€æ­¥é™ä½å¹³æ»‘åº¦ï¼Œæé«˜å“åº”é€Ÿåº¦
      analyser.minDecibels = -90;
      analyser.maxDecibels = -10;
      assistantAnalyserRef.current = analyser;
      
      source.connect(analyser);
      analyser.connect(audioContext.destination);
      console.log('åŠ©æ‰‹éŸ³é¢‘æºå·²è¿æ¥åˆ°åˆ†æå™¨', {
        fftSize: analyser.fftSize,
        frequencyBinCount: analyser.frequencyBinCount,
        smoothingTimeConstant: analyser.smoothingTimeConstant,
      });
      
      // å¯åŠ¨åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–ï¼ˆä½¿ç”¨ requestAnimationFrame æé«˜å“åº”é€Ÿåº¦ï¼‰
      const updateAssistantAudioVisualization = () => {
        if (!assistantAnalyserRef.current) {
          console.log('åŠ©æ‰‹åˆ†æå™¨ä¸å­˜åœ¨ï¼Œåœæ­¢æ›´æ–°');
          return;
        }
        
        // æ£€æŸ¥ isCalling çŠ¶æ€ï¼ˆä½¿ç”¨ ref è€Œä¸æ˜¯é—­åŒ…ä¸­çš„å€¼ï¼‰
        if (!isCallingRef.current) {
          console.log('ä¸åœ¨é€šè¯ä¸­ï¼Œåœæ­¢åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–');
          return;
        }
        
        try {
          const bufferLength = assistantAnalyserRef.current.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);
          assistantAnalyserRef.current.getByteFrequencyData(dataArray);
          
          // è®¡ç®—å¹³å‡éŸ³é‡å’Œæœ€å¤§å€¼ç”¨äºè°ƒè¯•ï¼ˆä»…åœ¨å¼€å‘ç¯å¢ƒï¼Œä¸”èŠ‚æµè¾“å‡ºï¼‰
          if (process.env.NODE_ENV === 'development') {
            const avgVolume = dataArray.reduce((sum, val) => sum + val, 0) / bufferLength;
            const maxVolume = Math.max(...Array.from(dataArray));
            
            // èŠ‚æµæ—¥å¿—è¾“å‡ºï¼ˆæ¯ 500ms è¾“å‡ºä¸€æ¬¡ï¼Œæˆ–éŸ³é‡å˜åŒ–è¶…è¿‡ 20%ï¼‰
            const now = Date.now();
            const lastLogTime = (assistantAnalyserRef.current as any).__lastLogTime || 0;
            const lastAvgVolume = (assistantAnalyserRef.current as any).__lastAvgVolume || 0;
            const volumeChange = Math.abs(avgVolume - lastAvgVolume) / (lastAvgVolume || 1);
            
            if (now - lastLogTime > 500 || volumeChange > 0.2) {
              if (avgVolume > 1 || maxVolume > 5) {
                console.log('ğŸµ åŠ©æ‰‹éŸ³é¢‘æ•°æ®æ›´æ–°:', {
                  å¹³å‡éŸ³é‡: avgVolume.toFixed(2),
                  æœ€å¤§å€¼: maxVolume,
                  æ•°æ®é•¿åº¦: bufferLength,
                });
                (assistantAnalyserRef.current as any).__lastLogTime = now;
                (assistantAnalyserRef.current as any).__lastAvgVolume = avgVolume;
              }
            }
          }
          
          setAssistantFrequencyData(dataArray);
          
          // ä½¿ç”¨ requestAnimationFrame æé«˜å“åº”é€Ÿåº¦ï¼ˆçº¦ 60fpsï¼‰
          assistantAnimationFrameRef.current = requestAnimationFrame(() => {
            updateAssistantAudioVisualization();
          }) as any;
        } catch (err) {
          console.error('æ›´æ–°åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–å¤±è´¥:', err);
          // å¦‚æœå‡ºé”™ï¼Œåœæ­¢æ›´æ–°
          if (assistantAnimationFrameRef.current) {
            cancelAnimationFrame(assistantAnimationFrameRef.current);
            assistantAnimationFrameRef.current = null;
          }
        }
      };
      
      // ç«‹å³å¯åŠ¨å¯è§†åŒ–å¾ªç¯ï¼ˆä¸å»¶è¿Ÿï¼‰
      // å› ä¸º isCallingRef å·²ç»åœ¨ startCall ä¸­è®¾ç½®äº†
      if (isCallingRef.current && assistantAnalyserRef.current) {
        console.log('âœ… ç«‹å³å¯åŠ¨åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–');
        updateAssistantAudioVisualization();
      } else {
        console.warn('âš ï¸ åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–å¯åŠ¨æ¡ä»¶ä¸æ»¡è¶³ï¼Œå»¶è¿Ÿå¯åŠ¨', {
          isCalling: isCallingRef.current,
          hasAnalyser: !!assistantAnalyserRef.current,
        });
        // å»¶è¿Ÿå¯åŠ¨ï¼Œç­‰å¾…æ¡ä»¶æ»¡è¶³
        setTimeout(() => {
          if (isCallingRef.current && assistantAnalyserRef.current) {
            console.log('âœ… å»¶è¿Ÿå¯åŠ¨åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–');
            updateAssistantAudioVisualization();
          } else {
            console.error('âŒ åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–å¯åŠ¨å¤±è´¥', {
              isCalling: isCallingRef.current,
              hasAnalyser: !!assistantAnalyserRef.current,
            });
          }
      }, 200);
      }
    } catch (err: any) {
      console.error('åˆå§‹åŒ–åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–å¤±è´¥:', err);
    }
  }, []);

  /**
   * è¿æ¥ Voice Agent
   */
  const connect = useCallback(async () => {
    try {
      setError(null);
      
      // è·å–é…ç½®
      const config = await loadConfig();
      
      // è·å– ephemeral client key (ä¸´æ—¶å¯†é’¥)
      const realtimeToken = await configApi.getRealtimeToken();
      console.log('è·å– Realtime Token æˆåŠŸ:', {
        tokenPrefix: realtimeToken.token.substring(0, 10) + '...',
        url: realtimeToken.url,
        model: realtimeToken.model,
      });
      
      // è·å– personality é…ç½®
      const personalityConfig = (personality as any)?.config || {};
      const voiceConfig = personalityConfig?.voice || {};
      const realtimeConfig = voiceConfig?.realtime || {};
      
      // è·å– instructionsï¼ˆä¼˜å…ˆä½¿ç”¨ realtime.instructionsï¼Œå¦åˆ™ä½¿ç”¨ system_promptï¼‰
      const instructions = realtimeConfig.instructions || personalityConfig?.ai?.system_prompt || 'You are a helpful assistant.';
      
      // åˆ›å»º RealtimeAgent
      const agent = new RealtimeAgent({
        name: 'cozychat-agent',
        instructions: instructions,
        voice: realtimeConfig.voice || 'shimmer',
      });
      
      // åˆ›å»ºç”¨æˆ·éŸ³é¢‘æµï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
      // æˆ‘ä»¬éœ€è¦è‡ªå·±åˆ›å»º mediaStreamï¼Œè¿™æ ·å¯ä»¥ä»å®ƒè·å–éŸ³é¢‘æ•°æ®ç”¨äºå¯è§†åŒ–
      const userMediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 24000,
          echoCancellation: true,
          noiseSuppression: true,
        }
      });
      userMediaStreamRef.current = userMediaStream;
      
      // åˆ›å»ºåŠ©æ‰‹éŸ³é¢‘å…ƒç´ ï¼ˆä»…ç”¨äºå¯è§†åŒ–ï¼Œä¸è‡ªåŠ¨æ’­æ”¾ï¼‰
      // æ³¨æ„ï¼šWebRTC transport ä¼šè‡ªåŠ¨å¤„ç†éŸ³é¢‘æ’­æ”¾ï¼Œæˆ‘ä»¬åªéœ€è¦å¯è§†åŒ–
      const assistantAudioElement = new Audio();
      assistantAudioElement.autoplay = false; // ç¦ç”¨è‡ªåŠ¨æ’­æ”¾ï¼Œé¿å…é‡å¤æ’­æ”¾
      assistantAudioElement.muted = false; // ä¸é™éŸ³ï¼Œä½†ç”± transport æ§åˆ¶æ’­æ”¾
      assistantAudioElementRef.current = assistantAudioElement;
      
      // åˆ›å»º WebRTC ä¼ è¾“å±‚ï¼ˆæµè§ˆå™¨ç¯å¢ƒï¼‰
      // ä¼ é€’æˆ‘ä»¬è‡ªå·±åˆ›å»ºçš„ mediaStream å’Œ audioElementï¼Œä»¥ä¾¿ç”¨äºå¯è§†åŒ–
      // æ³¨æ„ï¼šbaseUrl éœ€è¦æ˜¯å®Œæ•´çš„ç«¯ç‚¹ URLï¼ŒåŒ…æ‹¬ /v1/realtime/calls è·¯å¾„
      // SDK ä¸ä¼šè‡ªåŠ¨æ·»åŠ è·¯å¾„ï¼Œéœ€è¦æ‰‹åŠ¨æŒ‡å®šå®Œæ•´ URL
      let baseUrl = config.base_url;
      if (baseUrl.endsWith('/v1')) {
        baseUrl = baseUrl.slice(0, -3);
      } else if (baseUrl.endsWith('/v1/')) {
        baseUrl = baseUrl.slice(0, -4);
      }
      // ç¡®ä¿ baseUrl ä¸ä»¥ / ç»“å°¾
      baseUrl = baseUrl.replace(/\/$/, '');
      // æ·»åŠ  /v1/realtime/calls è·¯å¾„ï¼ˆWebRTC ç«¯ç‚¹ï¼‰
      const webrtcEndpoint = `${baseUrl}/v1/realtime/calls`;
      
      console.log('WebRTC Transport é…ç½®:', {
        baseUrl: baseUrl,
        webrtcEndpoint: webrtcEndpoint,
        hasMediaStream: !!userMediaStream,
        hasAudioElement: !!assistantAudioElement,
        useEphemeralKey: true, // ä½¿ç”¨ ephemeral key
      });
      
      const transport = new OpenAIRealtimeWebRTC({
        baseUrl: webrtcEndpoint, // ä½¿ç”¨å®Œæ•´çš„ç«¯ç‚¹ URLï¼ˆä¾‹å¦‚ï¼šhttps://oneapi.naivehero.top/v1/realtime/callsï¼‰
        // ä¸ä½¿ç”¨ useInsecureApiKeyï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨æœ‰ ephemeral key
        mediaStream: userMediaStream, // ä½¿ç”¨æˆ‘ä»¬è‡ªå·±åˆ›å»ºçš„éŸ³é¢‘æµ
        audioElement: assistantAudioElement, // ä½¿ç”¨æˆ‘ä»¬è‡ªå·±åˆ›å»ºçš„éŸ³é¢‘å…ƒç´ 
      });
      
      // åˆ›å»º RealtimeSessionï¼Œé…ç½®è¾“å…¥éŸ³é¢‘è½¬å½•
      // æ³¨æ„ï¼šé…ç½®æ ¼å¼å¿…é¡»æ­£ç¡®ï¼Œå¦åˆ™è½¬å½•åŠŸèƒ½ä¸ä¼šå¯ç”¨
      const sessionConfig = {
        inputAudioTranscription: {
          model: 'whisper-1', // ä½¿ç”¨ Whisper æ¨¡å‹è¿›è¡Œè½¬å½•
        },
        // å…¶ä»–å¯èƒ½çš„é…ç½®é¡¹
        inputAudioFormat: 'pcm16',
        outputAudioFormat: 'pcm16',
      };
      
      console.log('ğŸ“‹ åˆ›å»º RealtimeSessionï¼Œé…ç½®:', JSON.stringify(sessionConfig, null, 2));
      
      const session = new RealtimeSession(agent, {
        apiKey: realtimeToken.token, // ä½¿ç”¨ ephemeral key è€Œä¸æ˜¯ API key
        transport: transport, // ä½¿ç”¨è‡ªå®šä¹‰çš„ WebRTC ä¼ è¾“å±‚
        model: realtimeToken.model,
        // é…ç½®è¾“å…¥éŸ³é¢‘è½¬å½•ï¼ˆå…³é”®ï¼ï¼‰
        config: sessionConfig,
      });
      
      // éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®è®¾ç½®
      console.log('ğŸ“‹ Session åˆ›å»ºåï¼Œæ£€æŸ¥é…ç½®:', {
        hasConfig: !!(session as any).config,
        config: (session as any).config,
        hasInputAudioTranscription: !!(session as any).config?.inputAudioTranscription,
        sessionKeys: Object.keys(session as any),
      });
      
      // ä¿å­˜ webrtcEndpoint åˆ° session çš„æŸä¸ªåœ°æ–¹ï¼Œä»¥ä¾¿åœ¨ connect æ—¶ä½¿ç”¨
      (session as any).__webrtcEndpoint = webrtcEndpoint;
      
      // ========== æ­£ç¡®çš„äº‹ä»¶ç›‘å¬æ–¹å¼ ==========
      // æ ¹æ® OpenAI Realtime API æ–‡æ¡£ï¼Œåº”è¯¥ä½¿ç”¨ä»¥ä¸‹äº‹ä»¶ï¼š
      
      // 1. ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬äº‹ä»¶ï¼ˆå®Œæˆï¼‰
      // æ³¨æ„ï¼šè¿™ä¸ªäº‹ä»¶å¯èƒ½ä¸ä¼šè§¦å‘ï¼Œå¦‚æœé…ç½®ä¸æ­£ç¡®æˆ– SDK ç‰ˆæœ¬ä¸æ”¯æŒ
      session.on('input_audio_transcription.done', (event: any) => {
        const transcript = event?.transcript || event?.text || event?.content;
        console.log('ğŸ¤ input_audio_transcription.done äº‹ä»¶è§¦å‘:', { 
          transcript, 
          event,
          eventKeys: Object.keys(event || {}),
          fullEvent: JSON.stringify(event, null, 2),
        });
        if (transcript && typeof transcript === 'string' && transcript.trim() && callbacks?.onUserTranscript) {
          console.log('âœ… è·å–ç”¨æˆ·è½¬å½•æ–‡æœ¬:', transcript);
          callbacks.onUserTranscript(transcript);
        } else {
          console.warn('âš ï¸ input_audio_transcription.done äº‹ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„è½¬å½•æ–‡æœ¬:', {
            transcript,
            transcriptType: typeof transcript,
            hasCallback: !!callbacks?.onUserTranscript,
          });
        }
      });
      
      // ç›‘å¬æ‰€æœ‰å¯èƒ½çš„äº‹ä»¶ï¼Œç”¨äºè°ƒè¯•
      // æ³¨æ„ï¼šæŸäº›äº‹ä»¶å¯èƒ½ä¸å­˜åœ¨ï¼Œä½†ç›‘å¬å®ƒä»¬ä¸ä¼šæŠ¥é”™
      const debugEvents = [
        'input_audio_transcription.done',
        'input_audio_transcription.delta',
        'input_audio_transcription.partial',
        'conversation.item.input_audio_transcription.completed',
        'conversation.item.input_audio_transcription.delta',
      ];
      
      debugEvents.forEach((eventName) => {
        try {
          session.on(eventName as any, (event: any) => {
            console.log(`ğŸ” è°ƒè¯•äº‹ä»¶ ${eventName} è§¦å‘:`, event);
          });
        } catch (e) {
          // å¿½ç•¥ä¸å­˜åœ¨çš„ç›‘å¬å™¨
        }
      });
      
      // 2. ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬äº‹ä»¶ï¼ˆå¢é‡ï¼Œå¯é€‰ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰
      session.on('input_audio_transcription.delta', (event: any) => {
        const delta = event?.delta;
        console.log('ğŸ¤ input_audio_transcription.delta äº‹ä»¶:', { delta, event });
        // å¯ä»¥ç”¨äºå®æ—¶æ˜¾ç¤ºè½¬å½•è¿‡ç¨‹
      });
      
      // 3. åŠ©æ‰‹æ–‡æœ¬å›å¤äº‹ä»¶ï¼ˆå®Œæˆï¼‰
      session.on('response.text.done', (event: any) => {
        const text = event?.text || event?.content;
        console.log('ğŸ¤– response.text.done äº‹ä»¶:', { text, event });
              if (text && typeof text === 'string' && text.trim() && callbacks?.onAssistantTranscript) {
          console.log('âœ… è·å–åŠ©æ‰‹æ–‡æœ¬:', text);
                callbacks.onAssistantTranscript(text);
              }
      });
      
      // 4. åŠ©æ‰‹æ–‡æœ¬å›å¤äº‹ä»¶ï¼ˆå¢é‡ï¼Œå¯é€‰ï¼‰
      session.on('response.text.delta', (event: any) => {
        const delta = event?.delta;
        console.log('ğŸ¤– response.text.delta äº‹ä»¶:', { delta, event });
        // å¯ä»¥ç”¨äºå®æ—¶æ˜¾ç¤ºæ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹
      });
      
      // 5. ä» history_added å’Œ history_updated æå–æ–‡æœ¬ï¼ˆä¸»è¦æ–¹å¼ï¼Œå› ä¸ºä¸“ç”¨äº‹ä»¶å¯èƒ½ä¸å·¥ä½œï¼‰
      // ç”¨äºå»é‡çš„ Setï¼ˆå­˜å‚¨å·²å¤„ç†çš„æ¶ˆæ¯IDå’Œæ–‡æœ¬å†…å®¹ï¼‰
      const processedMessageIds = new Set<string>();
      const processedTexts = new Set<string>(); // å­˜å‚¨å·²å¤„ç†çš„æ–‡æœ¬å†…å®¹ï¼ˆæ¶ˆæ¯ID:æ–‡æœ¬å†…å®¹ï¼‰
      
      // æå–ç”¨æˆ·è½¬å½•æ–‡æœ¬çš„è¾…åŠ©å‡½æ•°
      const extractUserTranscript = (item: any): string | null => {
        // é¦–å…ˆæ£€æŸ¥ item çš„ç›´æ¥å­—æ®µ
        if (item.transcript && typeof item.transcript === 'string' && item.transcript.trim()) {
          return item.transcript.trim();
        }
        if (item.input_audio_transcript && typeof item.input_audio_transcript === 'string' && item.input_audio_transcript.trim()) {
          return item.input_audio_transcript.trim();
        }
        
        // æ£€æŸ¥ content æ•°ç»„
        if (Array.isArray(item.content)) {
          for (const c of item.content) {
            // ä¼˜å…ˆæ£€æŸ¥ input_audio ç±»å‹
            if (c.type === 'input_audio') {
              if (c.transcript && typeof c.transcript === 'string' && c.transcript.trim()) {
                return c.transcript.trim();
              }
              // æ£€æŸ¥ input_audio çš„å…¶ä»–å¯èƒ½å­—æ®µ
              if (c.input_audio_transcript && typeof c.input_audio_transcript === 'string' && c.input_audio_transcript.trim()) {
                return c.input_audio_transcript.trim();
              }
            }
            // æ£€æŸ¥ä»»ä½•åŒ…å« transcript çš„é¡¹
            if (c.transcript && typeof c.transcript === 'string' && c.transcript.trim()) {
              return c.transcript.trim();
            }
            // æ£€æŸ¥ text ç±»å‹ï¼ˆæŸäº›æƒ…å†µä¸‹è½¬å½•å¯èƒ½ä»¥ text å½¢å¼å­˜åœ¨ï¼‰
            if (c.type === 'text' && c.text && typeof c.text === 'string' && c.text.trim()) {
              return c.text.trim();
            }
          }
        }
        
        // å¦‚æœ content æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if (typeof item.content === 'string' && item.content.trim()) {
          return item.content.trim();
        }
        
        return null;
      };
      
      // æå–åŠ©æ‰‹æ–‡æœ¬çš„è¾…åŠ©å‡½æ•°
      const extractAssistantText = (item: any): string | null => {
        // æ£€æŸ¥ content æ•°ç»„
        if (Array.isArray(item.content)) {
          for (const c of item.content) {
            if (c.type === 'text' && c.text && typeof c.text === 'string') {
              return c.text.trim();
            }
            if (c.type === 'output_audio' && c.transcript && typeof c.transcript === 'string') {
              return c.transcript.trim();
            }
          }
        }
        
        // æ£€æŸ¥ç›´æ¥å­—æ®µ
        if (item.text && typeof item.text === 'string') {
          return item.text.trim();
        }
        
        return null;
      };
      
      session.on('history_added', (item: any) => {
        if (item.type === 'message') {
          const messageId = item.itemId || item.id;
          if (!messageId) {
            return; // æ²¡æœ‰æœ‰æ•ˆçš„æ¶ˆæ¯IDï¼Œè·³è¿‡
          }
          
          // æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡è¿™ä¸ªæ¶ˆæ¯ID
          if (processedMessageIds.has(messageId)) {
            return;
          }
          
          if (item.role === 'user') {
            const transcript = extractUserTranscript(item);
            if (transcript && callbacks?.onUserTranscript) {
              const textKey = `${messageId}:${transcript}`;
              if (!processedTexts.has(textKey)) {
                processedMessageIds.add(messageId);
                processedTexts.add(textKey);
                console.log('âœ… ä» history_added è·å–ç”¨æˆ·è½¬å½•:', transcript, 'æ¶ˆæ¯ID:', messageId);
                callbacks.onUserTranscript(transcript);
              }
            } else {
              // å¦‚æœæ²¡æœ‰è½¬å½•æ–‡æœ¬ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
              console.log('âš ï¸ history_added - ç”¨æˆ·æ¶ˆæ¯æ²¡æœ‰è½¬å½•æ–‡æœ¬:', {
                messageId,
                content: item.content,
                status: item.status,
                item: JSON.stringify(item, null, 2),
              });
            }
          } else if (item.role === 'assistant') {
            const text = extractAssistantText(item);
            if (text && callbacks?.onAssistantTranscript) {
              const textKey = `${messageId}:${text}`;
              if (!processedTexts.has(textKey)) {
                processedMessageIds.add(messageId);
                processedTexts.add(textKey);
                console.log('âœ… ä» history_added è·å–åŠ©æ‰‹æ–‡æœ¬:', text, 'æ¶ˆæ¯ID:', messageId);
                callbacks.onAssistantTranscript(text);
              }
            }
          }
        }
      });
      
      session.on('history_updated', (history: any[]) => {
        // éå†æ‰€æœ‰æ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è½¬å½•æ–‡æœ¬
        history.forEach((item: any) => {
          if (item.type === 'message') {
            const messageId = item.itemId || item.id;
            if (!messageId) {
              return; // æ²¡æœ‰æœ‰æ•ˆçš„æ¶ˆæ¯IDï¼Œè·³è¿‡
            }
            
            if (item.role === 'user') {
              const transcript = extractUserTranscript(item);
              if (transcript) {
                // ä½¿ç”¨æ¶ˆæ¯IDå’Œæ–‡æœ¬å†…å®¹ä½œä¸ºå”¯ä¸€æ ‡è¯†
                const textKey = `${messageId}:${transcript}`;
                
                // å¦‚æœä¹‹å‰æ²¡æœ‰å¤„ç†è¿‡è¿™ä¸ªæ–‡æœ¬
                if (!processedTexts.has(textKey) && callbacks?.onUserTranscript) {
                  processedMessageIds.add(messageId);
                  processedTexts.add(textKey);
                  console.log('âœ… ä» history_updated è·å–ç”¨æˆ·è½¬å½•:', transcript, 'æ¶ˆæ¯ID:', messageId);
                  callbacks.onUserTranscript(transcript);
                }
              } else {
                // å¦‚æœæ²¡æœ‰è½¬å½•æ–‡æœ¬ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
                console.log('âš ï¸ ç”¨æˆ·æ¶ˆæ¯æ²¡æœ‰è½¬å½•æ–‡æœ¬:', {
                  messageId,
                  content: item.content,
                  status: item.status,
                });
              }
            } else if (item.role === 'assistant') {
              const text = extractAssistantText(item);
              if (text) {
                // ä½¿ç”¨æ¶ˆæ¯IDå’Œæ–‡æœ¬å†…å®¹ä½œä¸ºå”¯ä¸€æ ‡è¯†
                const textKey = `${messageId}:${text}`;
                
                // å¦‚æœä¹‹å‰æ²¡æœ‰å¤„ç†è¿‡è¿™ä¸ªæ–‡æœ¬
                if (!processedTexts.has(textKey) && callbacks?.onAssistantTranscript) {
                  processedMessageIds.add(messageId);
                  processedTexts.add(textKey);
                  console.log('âœ… ä» history_updated è·å–åŠ©æ‰‹æ–‡æœ¬:', text, 'æ¶ˆæ¯ID:', messageId);
                  callbacks.onAssistantTranscript(text);
                }
              }
            }
          }
        });
      });
      
      // éŸ³é¢‘è½¬å½•æ–‡æœ¬å¢é‡æ›´æ–°äº‹ä»¶ï¼ˆå¦‚æœ SDK æ”¯æŒï¼‰
      // æ³¨æ„ï¼šè¿™ä¸ªäº‹ä»¶åœ¨æ–‡æœ¬è¿˜åœ¨ç”Ÿæˆæ—¶è§¦å‘ï¼Œå¯ä»¥ç”¨äºå®æ—¶æ˜¾ç¤º
      // ä½†æœ€ç»ˆæ–‡æœ¬ä¼šåœ¨ history_added æˆ– history_updated ä¸­è·å–
      // session.on('audio_transcript_delta', (_event: any) => {
      //   // event.deltaEvent åŒ…å« itemId, delta, responseId
      //   // å¯ä»¥æ ¹æ® itemId åˆ¤æ–­æ˜¯ç”¨æˆ·è¿˜æ˜¯åŠ©æ‰‹
      // });
      
      sessionRef.current = session;
      setIsConnected(true);
      
      console.log('Voice Agent è¿æ¥æˆåŠŸ');
    } catch (err: any) {
      console.error('è¿æ¥ Voice Agent å¤±è´¥:', err);
      setError(err.message || 'è¿æ¥å¤±è´¥');
      throw err;
    }
  }, [loadConfig, personality, callbacks]);

  /**
   * æ–­å¼€è¿æ¥
   */
  const disconnect = useCallback(() => {
    try {
      if (sessionRef.current) {
        sessionRef.current.close(); // ä½¿ç”¨ close() æ–¹æ³•æ–­å¼€è¿æ¥
        sessionRef.current = null;
      }
      
      // åœæ­¢ç”¨æˆ·éŸ³é¢‘æµ
      if (userMediaStreamRef.current) {
        userMediaStreamRef.current.getTracks().forEach(track => track.stop());
        userMediaStreamRef.current = null;
      }
      
      // åœæ­¢åŠ©æ‰‹éŸ³é¢‘å…ƒç´ 
      if (assistantAudioElementRef.current) {
        assistantAudioElementRef.current.pause();
        assistantAudioElementRef.current.src = '';
        assistantAudioElementRef.current = null;
      }
      
      // åœæ­¢éŸ³é¢‘å¯è§†åŒ–
      if (userAnimationFrameRef.current) {
        clearTimeout(userAnimationFrameRef.current as any);
        userAnimationFrameRef.current = null;
      }
      if (assistantAnimationFrameRef.current) {
        clearTimeout(assistantAnimationFrameRef.current as any);
        assistantAnimationFrameRef.current = null;
      }
      
             setUserFrequencyData(null);
             setAssistantFrequencyData(null);
             setIsConnected(false);
             setIsCalling(false);
             isCallingRef.current = false;
      
      console.log('æ–­å¼€ Voice Agent è¿æ¥');
    } catch (err) {
      console.error('æ–­å¼€è¿æ¥å¤±è´¥:', err);
    }
  }, []);

  /**
   * å¼€å§‹é€šè¯
   */
  const startCall = useCallback(async () => {
    if (!isConnected) {
      await connect();
    }
    
    try {
      if (!sessionRef.current) {
        throw new Error('Voice Agent æœªè¿æ¥');
      }
      
      // è·å– ephemeral keyï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
      const realtimeToken = await configApi.getRealtimeToken();
      
      // è·å– WebRTC ç«¯ç‚¹ URLï¼ˆä» transport æˆ– session ä¸­è·å–ï¼‰
      // æ³¨æ„ï¼šä¸è¦ä¼ é€’ url å‚æ•°ï¼Œè®© transport ä½¿ç”¨å®ƒè‡ªå·±çš„ baseUrl
      // å¦‚æœä¼ é€’äº† urlï¼Œä¼šè¦†ç›– transport çš„ baseUrlï¼Œå¯¼è‡´è·¯å¾„ä¸æ­£ç¡®
      const webrtcEndpoint = (sessionRef.current as any).__webrtcEndpoint;
      
      // æ£€æŸ¥ transport çš„å†…éƒ¨çŠ¶æ€
      const currentTransport = sessionRef.current?.transport;
      let transportInternalUrl = 'N/A';
      if (currentTransport instanceof OpenAIRealtimeWebRTC) {
        // å°è¯•è·å– transport çš„å†…éƒ¨ URLï¼ˆé€šè¿‡åå°„æˆ–ç›´æ¥è®¿é—®ï¼‰
        try {
          // @ts-ignore - è®¿é—®ç§æœ‰å±æ€§
          transportInternalUrl = currentTransport['#url'] || 'æ— æ³•è®¿é—®';
        } catch (e) {
          transportInternalUrl = 'æ— æ³•è®¿é—®ç§æœ‰å±æ€§';
        }
      }
      
      console.log('å‡†å¤‡è¿æ¥ RealtimeSession:', {
        hasEphemeralKey: !!realtimeToken.token,
        tokenPrefix: realtimeToken.token.substring(0, 10) + '...',
        model: realtimeToken.model,
        webrtcEndpoint: webrtcEndpoint,
        transportInternalUrl: transportInternalUrl,
        transportType: currentTransport?.constructor?.name,
      });
      
      try {
        console.log('å¼€å§‹è¿æ¥ RealtimeSession...');
        console.log('Transport çŠ¶æ€:', {
          status: currentTransport instanceof OpenAIRealtimeWebRTC ? currentTransport.status : 'N/A',
          hasTransport: !!currentTransport,
        });
        
        // ä¸ä¼ é€’ url å‚æ•°ï¼Œè®© transport ä½¿ç”¨å®ƒè‡ªå·±çš„ baseUrlï¼ˆwebrtcEndpointï¼‰
        // å°è¯•åœ¨ connect æ—¶ä¹Ÿä¼ é€’é…ç½®ï¼ˆæŸäº› SDK ç‰ˆæœ¬å¯èƒ½éœ€è¦è¿™æ ·åšï¼‰
        const connectConfig = {
          input_audio_transcription: {
            model: 'whisper-1',
          },
        };
        
        console.log('ğŸ“‹ è¿æ¥æ—¶ä¼ é€’é…ç½®:', JSON.stringify(connectConfig, null, 2));
        
        await sessionRef.current.connect({
          apiKey: realtimeToken.token, // ä½¿ç”¨ ephemeral key
          model: realtimeToken.model,
          // å°è¯•åœ¨ connect æ—¶ä¼ é€’é…ç½®
          config: connectConfig as any,
          // ä¸ä¼ é€’ urlï¼Œä½¿ç”¨ transport çš„ baseUrl
        });
        console.log('RealtimeSession è¿æ¥æˆåŠŸ');
        
        // è¾“å‡ºå½“å‰ session çš„é…ç½®ï¼Œç”¨äºè°ƒè¯•
        console.log('ğŸ“‹ Session è¿æ¥åé…ç½®æ£€æŸ¥:', {
          hasConfig: !!(sessionRef.current as any).config,
          config: (sessionRef.current as any).config,
          hasInputAudioTranscription: !!(sessionRef.current as any).config?.inputAudioTranscription,
          sessionKeys: Object.keys(sessionRef.current as any),
          // æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–é…ç½®ç›¸å…³çš„å±æ€§
          hasSessionConfig: !!(sessionRef.current as any).sessionConfig,
          hasSettings: !!(sessionRef.current as any).settings,
        });
        
        // å°è¯•é€šè¿‡ transport å‘é€ session.update æ¶ˆæ¯æ¥å¯ç”¨è½¬å½•
        // æ³¨æ„ï¼šè¿™æ˜¯ç›´æ¥æ“ä½œ transportï¼Œå¯èƒ½ä¸æ˜¯æ ‡å‡†æ–¹å¼ï¼Œä½†å€¼å¾—å°è¯•
        try {
          const currentTransport = sessionRef.current?.transport;
          if (currentTransport && typeof (currentTransport as any).send === 'function') {
            const updateMessage = {
              type: 'session.update',
              session: {
                input_audio_transcription: {
                  model: 'whisper-1',
                },
              },
            };
            console.log('ğŸ“¤ å°è¯•é€šè¿‡ transport.send å‘é€ session.update:', updateMessage);
            (currentTransport as any).send(updateMessage);
            console.log('âœ… session.update æ¶ˆæ¯å·²å‘é€');
          } else {
            console.warn('âš ï¸ transport æ²¡æœ‰ send æ–¹æ³•ï¼Œæ— æ³•å‘é€ session.update');
            // å°è¯•å…¶ä»–æ–¹å¼
            if (currentTransport && typeof (currentTransport as any).dispatch === 'function') {
              console.log('ğŸ“¤ å°è¯•é€šè¿‡ transport.dispatch å‘é€ session.update');
              (currentTransport as any).dispatch({
                type: 'session.update',
                session: {
                  input_audio_transcription: {
                    model: 'whisper-1',
                  },
                },
              });
            }
          }
        } catch (updateErr: any) {
          console.warn('âš ï¸ å‘é€ session.update å¤±è´¥:', {
            error: updateErr,
            message: updateErr?.message,
          });
        }
      } catch (connectErr: any) {
        console.error('RealtimeSession è¿æ¥å¤±è´¥:', {
          error: connectErr,
          message: connectErr?.message,
          stack: connectErr?.stack,
          webrtcEndpoint: webrtcEndpoint,
          errorName: connectErr?.name,
          errorCause: connectErr?.cause,
        });
        
        // æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        if (connectErr?.message?.includes('Failed to fetch')) {
          // æ£€æŸ¥æ˜¯å¦æ˜¯ CORS é—®é¢˜
          const isCorsError = connectErr?.message?.includes('CORS') || 
                             connectErr?.stack?.includes('CORS') ||
                             connectErr?.cause?.message?.includes('CORS');
          
          const errorMsg = `WebRTC è¿æ¥å¤±è´¥ (Failed to fetch)ã€‚

å¯èƒ½çš„åŸå› ï¼š
1. CORS é…ç½®é—®é¢˜ - æœåŠ¡å™¨æœªè®¾ç½®æ­£ç¡®çš„ CORS å¤´éƒ¨
2. æœåŠ¡å™¨ä¸æ”¯æŒ /v1/realtime/calls ç«¯ç‚¹
3. ç½‘ç»œè¿æ¥é—®é¢˜

è°ƒè¯•ä¿¡æ¯ï¼š
- WebRTC ç«¯ç‚¹: ${webrtcEndpoint}
- Transport å†…éƒ¨ URL: ${transportInternalUrl}
- æ˜¯å¦ CORS é”™è¯¯: ${isCorsError ? 'æ˜¯' : 'å¦'}

è¯·æ£€æŸ¥ï¼š
1. æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ Network æ ‡ç­¾é¡µï¼ŒæŸ¥çœ‹å®é™…è¯·æ±‚çš„ URL å’Œå“åº”
2. æœåŠ¡å™¨æ˜¯å¦æ­£ç¡®é…ç½®äº† CORS å¤´éƒ¨ï¼ˆAccess-Control-Allow-Origin ç­‰ï¼‰
3. æœåŠ¡å™¨æ˜¯å¦æ”¯æŒ /v1/realtime/calls ç«¯ç‚¹`;
          setError(errorMsg);
          
          console.error('è¯¦ç»†é”™è¯¯ä¿¡æ¯:', {
            error: connectErr,
            webrtcEndpoint,
            transportInternalUrl,
            isCorsError,
            suggestion: 'è¯·æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ Network æ ‡ç­¾é¡µï¼ŒæŸ¥çœ‹å®é™…è¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯',
          });
        }
        
        throw connectErr;
      }
      
      // ç­‰å¾…è¿æ¥å»ºç«‹åå†åˆå§‹åŒ–éŸ³é¢‘å¯è§†åŒ–
      const sessionTransport = sessionRef.current.transport;
      if (sessionTransport instanceof OpenAIRealtimeWebRTC) {
        await new Promise<void>((resolve) => {
          const checkConnection = () => {
            if (sessionTransport.status === 'connected') {
              resolve();
            } else {
              setTimeout(checkConnection, 100);
            }
          };
          checkConnection();
        });
        
        // ä» transport è·å–å®é™…çš„éŸ³é¢‘æµ
        // OpenAIRealtimeWebRTC å†…éƒ¨ä¼šè®¾ç½® audioElement.srcObject
        // æˆ‘ä»¬éœ€è¦ç­‰å¾…è¿™ä¸ªè®¾ç½®å®Œæˆ
        await new Promise<void>((resolve) => {
          const checkAudioElement = () => {
            if (assistantAudioElementRef.current?.srcObject) {
              console.log('åŠ©æ‰‹éŸ³é¢‘å…ƒç´ å·²è®¾ç½® srcObject');
              resolve();
            } else {
              setTimeout(checkAudioElement, 100);
            }
          };
          // æœ€å¤šç­‰å¾… 5 ç§’
          setTimeout(() => {
            console.warn('ç­‰å¾…åŠ©æ‰‹éŸ³é¢‘å…ƒç´ è¶…æ—¶');
            resolve();
          }, 5000);
          checkAudioElement();
        });
      }
      
      // å…ˆè®¾ç½® isCalling çŠ¶æ€ï¼Œè¿™æ ·éŸ³é¢‘å¯è§†åŒ–æ‰èƒ½æ­£å¸¸å·¥ä½œ
      setIsCalling(true);
      isCallingRef.current = true;
      
      // åˆå§‹åŒ–éŸ³é¢‘å¯è§†åŒ–
      // ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„ mediaStreamï¼ˆç”¨æˆ·éŸ³é¢‘ï¼‰
      if (userMediaStreamRef.current) {
        console.log('åˆå§‹åŒ–ç”¨æˆ·éŸ³é¢‘å¯è§†åŒ–ï¼Œstream tracks:', userMediaStreamRef.current.getTracks().length);
        await initUserAudioVisualization(userMediaStreamRef.current);
      }
      
      // ä½¿ç”¨ transport è®¾ç½®çš„ audioElementï¼ˆåŠ©æ‰‹éŸ³é¢‘ï¼‰
      // å»¶è¿Ÿä¸€ç‚¹ï¼Œç¡®ä¿éŸ³é¢‘æµå·²ç»è®¾ç½®å¥½
      if (assistantAudioElementRef.current) {
        console.log('åˆå§‹åŒ–åŠ©æ‰‹éŸ³é¢‘å¯è§†åŒ–ï¼ŒsrcObject:', !!assistantAudioElementRef.current.srcObject);
        
        // ç­‰å¾…éŸ³é¢‘æµè®¾ç½®å®Œæˆï¼Œç„¶ååˆå§‹åŒ–å¯è§†åŒ–
        const initAssistantVisualization = () => {
          if (assistantAudioElementRef.current?.srcObject) {
            console.log('åŠ©æ‰‹éŸ³é¢‘æµå·²å‡†å¤‡å¥½ï¼Œå¼€å§‹åˆå§‹åŒ–å¯è§†åŒ–');
        initAssistantAudioVisualization(assistantAudioElementRef.current);
          } else {
            // å¦‚æœè¿˜æ²¡æœ‰ srcObjectï¼Œç­‰å¾…ä¸€ä¸‹å†è¯•
            console.log('åŠ©æ‰‹éŸ³é¢‘æµå°šæœªå‡†å¤‡å¥½ï¼Œç­‰å¾…...');
            setTimeout(initAssistantVisualization, 200);
          }
        };
        
        // å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç¡®ä¿ isCallingRef å·²è®¾ç½®ä¸”éŸ³é¢‘æµå·²å‡†å¤‡å¥½
        setTimeout(initAssistantVisualization, 300);
      }
      
      // å¦å¤–ï¼Œå°è¯•ä» transport ç›´æ¥è·å–éŸ³é¢‘æµï¼ˆå¦‚æœæ”¯æŒï¼‰
      if (sessionTransport instanceof OpenAIRealtimeWebRTC) {
        try {
          // æ£€æŸ¥ transport æ˜¯å¦æœ‰ getMediaStream æ–¹æ³•
          const transportStream = (sessionTransport as any).getMediaStream?.();
          if (transportStream instanceof MediaStream) {
            console.log('ä» transport è·å–éŸ³é¢‘æµæˆåŠŸï¼Œtracks:', transportStream.getTracks().length);
            // å¯ä»¥å°è¯•ä½¿ç”¨è¿™ä¸ªæµè¿›è¡Œå¯è§†åŒ–ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
          }
        } catch (e) {
          console.warn('æ— æ³•ä» transport è·å–éŸ³é¢‘æµ:', e);
        }
      }
      
      console.log('å¼€å§‹è¯­éŸ³é€šè¯');
    } catch (err: any) {
      console.error('å¼€å§‹é€šè¯å¤±è´¥:', err);
      setError(err.message || 'å¼€å§‹é€šè¯å¤±è´¥');
      throw err;
    }
  }, [isConnected, connect, loadConfig, initUserAudioVisualization, initAssistantAudioVisualization]);

  /**
   * ç»“æŸé€šè¯
   */
  const endCall = useCallback(async () => {
    try {
      if (sessionRef.current) {
        sessionRef.current.close();
        sessionRef.current = null;
      }
      
      // åœæ­¢éŸ³é¢‘å¯è§†åŒ–
      if (userAnimationFrameRef.current) {
        cancelAnimationFrame(userAnimationFrameRef.current);
        userAnimationFrameRef.current = null;
      }
      if (assistantAnimationFrameRef.current) {
        cancelAnimationFrame(assistantAnimationFrameRef.current);
        assistantAnimationFrameRef.current = null;
      }
      
      // æ¸…ç†åŠ©æ‰‹éŸ³é¢‘æºå’Œä¸Šä¸‹æ–‡
      if (assistantSourceRef.current) {
        try {
          assistantSourceRef.current.disconnect();
        } catch (e) {
          // å¿½ç•¥æ–­å¼€è¿æ¥é”™è¯¯
        }
        assistantSourceRef.current = null;
      }
      
      if (assistantAudioContextRef.current) {
        try {
          assistantAudioContextRef.current.close();
        } catch (e) {
          // å¿½ç•¥å…³é—­é”™è¯¯
        }
        assistantAudioContextRef.current = null;
      }
      
      // æ¸…ç†éŸ³é¢‘æµ
      if (userMediaStreamRef.current) {
        userMediaStreamRef.current.getTracks().forEach((track) => track.stop());
        userMediaStreamRef.current = null;
      }
      
      setIsCalling(false);
      isCallingRef.current = false;
      setUserFrequencyData(null);
      setAssistantFrequencyData(null);
      
      console.log('ç»“æŸè¯­éŸ³é€šè¯');
    } catch (err: any) {
      console.error('ç»“æŸé€šè¯å¤±è´¥:', err);
      setError(err.message || 'ç»“æŸé€šè¯å¤±è´¥');
    }
  }, []);

  // æ¸…ç†
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    isConnected,
    isCalling,
    error,
    userFrequencyData,
    assistantFrequencyData,
    connect,
    disconnect,
    startCall,
    endCall,
  };
};
