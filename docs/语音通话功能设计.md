# è¯­éŸ³é€šè¯åŠŸèƒ½è®¾è®¡

## æ¶æ„æ¦‚è¿°

### æ ¸å¿ƒåŸåˆ™

1. **å‰ç«¯ç›´æ¥ä½¿ç”¨ OpenAI Voice Agent SDK**ï¼šæµè§ˆå™¨ç›´æ¥è¿æ¥ OpenAI Realtime API
2. **åç«¯ä»…æä¾›é…ç½®å’ŒåŸºç¡€æœåŠ¡**ï¼šæä¾› API keyã€base_urlï¼Œä»¥åŠæŒ‰éœ€çš„ STT/TTS/LLM æœåŠ¡
3. **èŒè´£åˆ†ç¦»**ï¼šè¯­éŸ³é€šè¯é€»è¾‘åœ¨å‰ç«¯ï¼Œåç«¯ä¸å‚ä¸å®æ—¶è¯­éŸ³æµå¤„ç†

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å‰ç«¯ (æµè§ˆå™¨)                        â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  OpenAI Voice Agent SDK (@openai/agents)       â”‚  â”‚
â”‚  â”‚  - ç›´æ¥è¿æ¥ OpenAI Realtime API                 â”‚  â”‚
â”‚  â”‚  - å¤„ç†éŸ³é¢‘æµã€æ–‡æœ¬è½¬å½•ã€è¯­éŸ³åˆæˆ                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†‘                               â”‚
â”‚                          â”‚ è·å–é…ç½®                      â”‚
â”‚                          â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åç«¯ (FastAPI)                     â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. é…ç½®API: æä¾› OpenAI API key & base_url     â”‚  â”‚
â”‚  â”‚  2. STT API: /v1/audio/transcriptions (æŒ‰éœ€)    â”‚  â”‚
â”‚  â”‚  3. TTS API: /v1/audio/speech (æŒ‰éœ€)           â”‚  â”‚
â”‚  â”‚  4. LLM API: /v1/chat/completions (æŒ‰éœ€)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## UIè®¾è®¡æ–¹æ¡ˆ

### è¯­éŸ³é€šè¯æŒ‡ç¤ºå™¨ä½ç½®

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Header: Logo + Title + User Menu]              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¤ è¯­éŸ³é€šè¯ä¸­  00:23  [ç»“æŸé€šè¯]  â† æŒ‡ç¤ºå™¨      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  [æ¶ˆæ¯åˆ—è¡¨åŒºåŸŸ]                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ åŠ©æ‰‹: ä½ å¥½ï¼                            â”‚   â”‚
â”‚  â”‚ æˆ‘(è¯­éŸ³): ä½ å¥½ï¼Œæˆ‘æƒ³é—®ä¸€ä¸ªé—®é¢˜          â”‚   â”‚
â”‚  â”‚ åŠ©æ‰‹(è¯­éŸ³): å¥½çš„ï¼Œè¯·è¯´                  â”‚   â”‚
â”‚  â”‚ æˆ‘(è¯­éŸ³): ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ              â”‚   â”‚
â”‚  â”‚ åŠ©æ‰‹(è¯­éŸ³): ä»Šå¤©å¤©æ°”å¾ˆå¥½...             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [è¾“å…¥æ¡†åŒºåŸŸ - é€šè¯ä¸­ç¦ç”¨]                        â”‚
â”‚  [æ–‡æœ¬è¾“å…¥æ¡†] [å‘é€æŒ‰é’®] [è¯­éŸ³é€šè¯æŒ‰é’®]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŒ‡ç¤ºå™¨è®¾è®¡

**ä½ç½®**: å›ºå®šåœ¨èŠå¤©å®¹å™¨é¡¶éƒ¨ï¼ˆHeaderä¸‹æ–¹ï¼Œæ¶ˆæ¯åˆ—è¡¨ä¸Šæ–¹ï¼‰

**æ ·å¼**:
- èƒŒæ™¯è‰²: `var(--primary-color)`ï¼ˆä¸»é¢˜è‰²ï¼‰
- æ–‡å­—é¢œè‰²: ç™½è‰²
- é«˜åº¦: 48px
- å†…è¾¹è·: 12px 16px
- è¾¹æ¡†: åº•éƒ¨1pxå®çº¿ï¼Œé¢œè‰²ä¸èƒŒæ™¯ç›¸åŒ

**å†…å®¹å¸ƒå±€**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤  è¯­éŸ³é€šè¯ä¸­    00:23    [ç»“æŸé€šè¯]      â”‚
â”‚ å›¾æ ‡  çŠ¶æ€æ–‡å­—    æ—¶é•¿      ç»“æŸæŒ‰é’®         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç»„ä»¶ç»“æ„**:
- å·¦ä¾§: ğŸ¤ å›¾æ ‡ + "è¯­éŸ³é€šè¯ä¸­" æ–‡å­—
- ä¸­é—´: é€šè¯æ—¶é•¿ï¼ˆMM:SSæ ¼å¼ï¼Œå®æ—¶æ›´æ–°ï¼‰
- å³ä¾§: "ç»“æŸé€šè¯"æŒ‰é’®ï¼ˆçº¢è‰²èƒŒæ™¯ï¼Œç™½è‰²æ–‡å­—ï¼‰

### æ¶ˆæ¯æ˜¾ç¤º

**æ™®é€šæ¶ˆæ¯**:
- ç”¨æˆ·: "ä½ å¥½"
- åŠ©æ‰‹: "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"

**è¯­éŸ³é€šè¯æ¶ˆæ¯**:
- ç”¨æˆ·: "æˆ‘(è¯­éŸ³) ä½ å¥½ï¼Œæˆ‘æƒ³é—®ä¸€ä¸ªé—®é¢˜"
- åŠ©æ‰‹: "åŠ©æ‰‹(è¯­éŸ³) å¥½çš„ï¼Œè¯·è¯´"

**æ ·å¼åŒºåˆ«**:
- è¯­éŸ³æ¶ˆæ¯åœ¨è§’è‰²åç§°åæ·»åŠ  `(è¯­éŸ³)` æ ‡ç­¾
- å¯ä»¥ä½¿ç”¨ä¸åŒé¢œè‰²æˆ–å›¾æ ‡åŒºåˆ†ï¼ˆå¯é€‰ï¼‰

## æŠ€æœ¯å®ç°

### åç«¯å®ç°

#### 1. æ–°å¢é…ç½®APIç«¯ç‚¹

**æ–‡ä»¶**: `backend/app/api/v1/config.py`ï¼ˆæ–°å»ºï¼‰

```python
@router.get("/openai-config")
async def get_openai_config(
    user: User = Depends(get_current_active_user)
):
    """
    è·å– OpenAI é…ç½®ï¼ˆä¾›å‰ç«¯ä½¿ç”¨ï¼‰
    
    è¿”å›:
        {
            "api_key": "sk-xxx",
            "base_url": "https://api.openai.com/v1"
        }
    """
    return {
        "api_key": settings.openai_api_key,
        "base_url": settings.openai_base_url
    }
```

**å®‰å…¨è€ƒè™‘**:
- âœ… éœ€è¦ç”¨æˆ·è®¤è¯ï¼ˆJWT tokenï¼‰
- âœ… ä»…è¿”å›é…ç½®ï¼Œä¸æš´éœ²å…¶ä»–æ•æ„Ÿä¿¡æ¯
- âš ï¸ å¦‚æœæ‹…å¿ƒ API key æ³„éœ²ï¼Œå¯ä»¥è€ƒè™‘ï¼š
  - ä½¿ç”¨ä¸´æ—¶ tokenï¼ˆçŸ­æœŸæœ‰æ•ˆï¼‰
  - æˆ–è€…å‰ç«¯é€šè¿‡åç«¯ä»£ç†ï¼ˆä½†ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºä¸æƒ³è¿™æ ·åšï¼‰

#### 2. ä¿ç•™ç°æœ‰API

- âœ… `backend/app/api/v1/audio.py` - STT/TTS REST APIï¼ˆæŒ‰éœ€ä½¿ç”¨ï¼‰
- âœ… `backend/app/api/v1/chat.py` - LLM chat_completion APIï¼ˆæŒ‰éœ€ä½¿ç”¨ï¼‰
- âœ… `backend/app/engines/voice/stt/` - STT å¼•æ“
- âœ… `backend/app/engines/voice/tts/` - TTS å¼•æ“

#### 3. åˆ é™¤ä¸éœ€è¦çš„ä»£ç 

- âŒ `backend/app/api/v1/websocket.py` - åˆ é™¤ Realtime WebSocket è·¯ç”±
- âŒ `backend/app/engines/voice/realtime/` - åˆ é™¤æ•´ä¸ªç›®å½•ï¼ˆRealtime ä»£ç†å®ç°ï¼‰

### å‰ç«¯å®ç°

#### 1. å®‰è£… OpenAI Agents SDK

```bash
cd frontend
pnpm add @openai/agents zod@3
```

**æ³¨æ„**: 
- `@openai/agents` æ˜¯ä¸»åŒ…
- `zod@3` æ˜¯å¿…éœ€çš„ä¾èµ–ï¼ˆç”¨äºç±»å‹éªŒè¯ï¼‰
- å¦‚æœåªéœ€è¦æµè§ˆå™¨ç‰ˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨ `@openai/agents-realtime`ï¼ˆç‹¬ç«‹åŒ…ï¼‰

#### 2. åˆ›å»ºé…ç½®æœåŠ¡

**æ–‡ä»¶**: `frontend/src/services/config.ts`ï¼ˆæ–°å»ºï¼‰

```typescript
import { apiClient } from './api';

export interface OpenAIConfig {
  api_key: string;
  base_url: string;
}

/**
 * é…ç½®APIæœåŠ¡
 */
export const configApi = {
  /**
   * è·å– OpenAI é…ç½®
   */
  async getOpenAIConfig(): Promise<OpenAIConfig> {
    return apiClient.get<OpenAIConfig>('/v1/config/openai-config');
  },
};
```

#### 3. åˆ›å»º Voice Agent Hook

**æ–‡ä»¶**: `frontend/src/hooks/useVoiceAgent.ts`ï¼ˆæ–°å»ºï¼Œæ›¿ä»£ useRealtimeVoice.tsï¼‰

```typescript
import { useState, useRef, useCallback, useEffect } from 'react';
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';
import { useQuery } from '@tanstack/react-query';
import { configApi } from '@/services/config';
import { personalityApi } from '@/services/personality';
import type { OpenAIConfig } from '@/services/config';
import type { Personality } from '@/types/personality';

export interface UseVoiceAgentReturn {
  /** æ˜¯å¦å·²è¿æ¥ */
  isConnected: boolean;
  /** æ˜¯å¦æ­£åœ¨é€šè¯ */
  isCalling: boolean;
  /** è¿æ¥ Voice Agent */
  connect: () => Promise<void>;
  /** æ–­å¼€è¿æ¥ */
  disconnect: () => void;
  /** å¼€å§‹é€šè¯ */
  startCall: () => Promise<void>;
  /** ç»“æŸé€šè¯ */
  endCall: () => void;
  /** ç”¨æˆ·æ–‡æœ¬è½¬å½•å›è°ƒ */
  onUserTranscript?: (text: string) => void;
  /** åŠ©æ‰‹æ–‡æœ¬è½¬å½•å›è°ƒ */
  onAssistantTranscript?: (text: string) => void;
  /** é”™è¯¯ä¿¡æ¯ */
  error: string | null;
}

/**
 * Voice Agent Hook
 * 
 * ä½¿ç”¨ OpenAI Agents SDK çš„ RealtimeSession å®ç°è¯­éŸ³é€šè¯
 * 
 * å‚è€ƒæ–‡æ¡£ï¼š
 * - https://openai.github.io/openai-agents-js/guides/voice-agents/
 * - https://openai.github.io/openai-agents-js/guides/voice-agents/quickstart/
 */
export const useVoiceAgent = (
  sessionId?: string,
  personalityId?: string,
  callbacks?: {
    onUserTranscript?: (text: string) => void;
    onAssistantTranscript?: (text: string) => void;
  }
): UseVoiceAgentReturn => {
  const [isConnected, setIsConnected] = useState(false);
  const [isCalling, setIsCalling] = useState(false);
  const [error, setError] = useState<string | null>(null);
  
  const sessionRef = useRef<RealtimeSession | null>(null);
  const agentRef = useRef<RealtimeAgent | null>(null);
  const configRef = useRef<OpenAIConfig | null>(null);

  // è·å– personality é…ç½®
  const { data: personality } = useQuery({
    queryKey: ['personality', personalityId],
    queryFn: () => personalityApi.getPersonality(personalityId!),
    enabled: !!personalityId,
    staleTime: 10 * 60 * 1000, // 10åˆ†é’Ÿ
  });

  /**
   * è·å– OpenAI é…ç½®
   */
  const loadConfig = useCallback(async () => {
    if (configRef.current) {
      return configRef.current;
    }
    
    const config = await configApi.getOpenAIConfig();
    configRef.current = config;
    return config;
  }, []);

  /**
   * è¿æ¥ Voice Agent
   */
  const connect = useCallback(async () => {
    try {
      setError(null);
      
      // 1. è·å–é…ç½®
      const config = await loadConfig();
      
      // 2. åˆ›å»º RealtimeAgentï¼ˆå®šä¹‰ Agent çš„è¡Œä¸ºï¼‰
      // ä¼˜å…ˆä½¿ç”¨ personality.voice.realtime.instructions
      // å¦‚æœä¸å­˜åœ¨ï¼Œå›é€€åˆ° personality.ai.system_prompt
      // æ³¨æ„ï¼špersonality ç±»å‹å¯èƒ½éœ€è¦æ‰©å±•ä»¥åŒ…å«å®Œæ•´é…ç½®
      const realtimeConfig = (personality as any)?.voice?.realtime || {};
      const aiConfig = (personality as any)?.ai || {};
      
      const instructions = realtimeConfig.instructions 
        || aiConfig.system_prompt 
        || 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€‚';
      
      const agent = new RealtimeAgent({
        name: personality?.name || 'CozyChat Assistant',
        instructions: instructions,
      });
      
      agentRef.current = agent;
      
      // 3. åˆ›å»º RealtimeSessionï¼ˆç®¡ç†è¿æ¥å’ŒéŸ³é¢‘ï¼‰
      // åœ¨æµè§ˆå™¨ä¸­ï¼Œé»˜è®¤ä½¿ç”¨ WebRTCï¼Œä¼šè‡ªåŠ¨å¤„ç†éŸ³é¢‘è¾“å…¥è¾“å‡º
      // ä» personality é…ç½®ä¸­è·å– voice å’Œ model è®¾ç½®
      const voice = realtimeConfig.voice || 'shimmer';
      const model = realtimeConfig.model || 'gpt-4o-realtime-preview-2024-10-01';
      
      const session = new RealtimeSession(agent, {
        model: model,
        // é…ç½®éŸ³é¢‘æ ¼å¼å’Œè½¬å½•
        config: {
          inputAudioFormat: 'pcm16',
          outputAudioFormat: 'pcm16',
          inputAudioTranscription: {
            model: 'whisper-1',
          },
          voice: voice, // ä» personality é…ç½®è·å–
        },
      });
      
      sessionRef.current = session;
      
      // 4. è®¾ç½®äº‹ä»¶ç›‘å¬
      // ç›‘å¬ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬äº‹ä»¶
      session.on('input_audio_transcription.done', (event: any) => {
        const text = event.transcript;
        if (text && callbacks?.onUserTranscript) {
          callbacks.onUserTranscript(text);
        }
      });
      
      // ç›‘å¬åŠ©æ‰‹å›å¤æ–‡æœ¬äº‹ä»¶
      session.on('response.text.done', (event: any) => {
        const text = event.text;
        if (text && callbacks?.onAssistantTranscript) {
          callbacks.onAssistantTranscript(text);
        }
      });
      
      // ç›‘å¬é”™è¯¯äº‹ä»¶
      session.on('error', (error: any) => {
        setError(error.message || 'è¿æ¥é”™è¯¯');
        console.error('RealtimeSession error:', error);
      });
      
      // 5. è¿æ¥åˆ° OpenAI Realtime API
      await session.connect({
        apiKey: config.api_key,
        baseURL: config.base_url,
      });
      
      setIsConnected(true);
    } catch (err: any) {
      setError(err.message || 'è¿æ¥å¤±è´¥');
      throw err;
    }
  }, [loadConfig, personality, callbacks]);

  /**
   * å¼€å§‹é€šè¯
   */
  const startCall = useCallback(async () => {
    if (!sessionRef.current) {
      await connect();
    }
    
    try {
      const session = sessionRef.current!;
      
      // å¼€å§‹ä¼šè¯ï¼ˆWebRTC ä¼šè‡ªåŠ¨å¼€å§‹éŸ³é¢‘æµï¼‰
      await session.start();
      setIsCalling(true);
    } catch (err: any) {
      setError(err.message || 'å¼€å§‹é€šè¯å¤±è´¥');
      throw err;
    }
  }, [connect]);

  /**
   * ç»“æŸé€šè¯
   */
  const endCall = useCallback(async () => {
    if (sessionRef.current) {
      try {
        await sessionRef.current.stop();
        setIsCalling(false);
      } catch (err: any) {
        console.error('Failed to stop session:', err);
      }
    }
  }, []);

  /**
   * æ–­å¼€è¿æ¥
   */
  const disconnect = useCallback(async () => {
    if (sessionRef.current) {
      try {
        await sessionRef.current.disconnect();
      } catch (err: any) {
        console.error('Failed to disconnect session:', err);
      }
      sessionRef.current = null;
    }
    agentRef.current = null;
    setIsConnected(false);
    setIsCalling(false);
  }, []);

  // æ¸…ç†
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    isConnected,
    isCalling,
    connect,
    disconnect,
    startCall,
    endCall,
    onUserTranscript: callbacks?.onUserTranscript,
    onAssistantTranscript: callbacks?.onAssistantTranscript,
    error,
  };
};
```

#### 4. çŠ¶æ€ç®¡ç†ï¼ˆZustandï¼‰

**æ–‡ä»¶**: `frontend/src/store/slices/chatSlice.ts`ï¼ˆä¿®æ”¹ï¼‰

```typescript
// ä¿ç•™ç°æœ‰çš„è¯­éŸ³é€šè¯çŠ¶æ€
interface ChatState {
  // ... å…¶ä»–çŠ¶æ€
  isVoiceCallActive: boolean;
  voiceCallMessages: Message[];
  voiceCallStartTime: number | null;
}

interface ChatActions {
  // ... å…¶ä»–æ“ä½œ
  startVoiceCall: () => void;
  endVoiceCall: () => void;
  addVoiceCallMessage: (message: Message) => void;
  clearVoiceCallMessages: () => void;
}
```

#### 5. ç»„ä»¶é›†æˆ

**æ–‡ä»¶**: `frontend/src/features/chat/components/EnhancedChatContainer.tsx`ï¼ˆä¿®æ”¹ï¼‰

```typescript
// ä½¿ç”¨æ–°çš„ useVoiceAgent Hook
import { useVoiceAgent } from '@/hooks/useVoiceAgent';

const EnhancedChatContainer: React.FC<Props> = ({ ... }) => {
  // ... å…¶ä»–ä»£ç 
  
  // useVoiceAgent å†…éƒ¨ä¼šè‡ªåŠ¨è·å– personality é…ç½®
  const { 
    isCalling, 
    startCall, 
    endCall,
    error: voiceError
  } = useVoiceAgent(
    currentSessionId,
    personalityId, // ä¼ å…¥ personalityIdï¼ŒHook å†…éƒ¨ä¼šè·å–é…ç½®
    {
      onUserTranscript: (text) => {
        // æ·»åŠ åˆ°è¯­éŸ³é€šè¯æ¶ˆæ¯åˆ—è¡¨
        addVoiceCallMessage({
          role: 'user',
          content: text,
          timestamp: new Date(),
          isVoiceCall: true,
        });
      },
      onAssistantTranscript: (text) => {
        // æ·»åŠ åˆ°è¯­éŸ³é€šè¯æ¶ˆæ¯åˆ—è¡¨
        addVoiceCallMessage({
          role: 'assistant',
          content: text,
          timestamp: new Date(),
          isVoiceCall: true,
        });
      },
    }
  );
  
  // æ˜¾ç¤ºé”™è¯¯
  useEffect(() => {
    if (voiceError) {
      showError(voiceError, 'è¯­éŸ³é€šè¯é”™è¯¯');
    }
  }, [voiceError]);
  
  // è¯­éŸ³é€šè¯æŒ‰é’®ç‚¹å‡»å¤„ç†
  const handleVoiceCallClick = async () => {
    if (isCalling) {
      endCall();
      // ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
      await saveVoiceCallMessages();
    } else {
      try {
        await startCall();
        startVoiceCall();
      } catch (err: any) {
        showError(err, 'å¼€å§‹è¯­éŸ³é€šè¯å¤±è´¥');
      }
    }
  };
  
  // ... å…¶ä»–ä»£ç 
};
```

#### 6. æ¶ˆæ¯ä¿å­˜

**æ–‡ä»¶**: `frontend/src/services/chat.ts`ï¼ˆä¿ç•™ç°æœ‰æ–¹æ³•ï¼‰

```typescript
// ä¿ç•™ç°æœ‰çš„ saveVoiceCallMessages æ–¹æ³•
export const chatApi = {
  // ... å…¶ä»–æ–¹æ³•
  
  /**
   * ä¿å­˜è¯­éŸ³é€šè¯æ¶ˆæ¯
   */
  async saveVoiceCallMessages(
    sessionId: string,
    messages: VoiceCallMessage[]
  ): Promise<void> {
    await apiClient.post('/v1/chat/voice-call-messages', {
      session_id: sessionId,
      messages,
    });
  },
};
```

## æ•°æ®æµ

```
ç”¨æˆ·ç‚¹å‡»è¯­éŸ³é€šè¯æŒ‰é’®
  â†“
å‰ç«¯: ä»åç«¯è·å– OpenAI é…ç½®ï¼ˆapi_key, base_urlï¼‰
  â†“
å‰ç«¯: åˆ›å»º RealtimeAgentï¼ˆå®šä¹‰ Agent è¡Œä¸ºï¼‰
  â†“
å‰ç«¯: åˆ›å»º RealtimeSessionï¼ˆä½¿ç”¨ WebRTC ä¼ è¾“ï¼Œè‡ªåŠ¨å¤„ç†éŸ³é¢‘ï¼‰
  â†“
å‰ç«¯: è¿æ¥ OpenAI Realtime APIï¼ˆæµè§ˆå™¨ â†’ OpenAIï¼Œä½¿ç”¨ WebRTCï¼‰
  â†“
å‰ç«¯: å¼€å§‹ä¼šè¯ï¼ˆè‡ªåŠ¨å¼€å§‹éŸ³é¢‘æµï¼‰
  â†“
ç”¨æˆ·è¯´è¯ â†’ WebRTC éŸ³é¢‘æµ â†’ OpenAI Realtime API â†’ å®æ—¶å¤„ç†
  â†“
å‰ç«¯: ç›‘å¬äº‹ä»¶
  - input_audio_transcription.done â†’ ç”¨æˆ·æ–‡æœ¬è½¬å½•
  - response.text.done â†’ åŠ©æ‰‹æ–‡æœ¬å›å¤
  - response.audio.delta â†’ åŠ©æ‰‹è¯­éŸ³æµï¼ˆè‡ªåŠ¨æ’­æ”¾ï¼‰
  â†“
å‰ç«¯: æ›´æ–° voiceCallMessages â†’ æ˜¾ç¤ºåœ¨æ¶ˆæ¯åˆ—è¡¨
  â†“
ç”¨æˆ·ç‚¹å‡»ç»“æŸé€šè¯
  â†“
å‰ç«¯: åœæ­¢ RealtimeSession
  â†“
å‰ç«¯: æ–­å¼€è¿æ¥
  â†“
å‰ç«¯: è°ƒç”¨åç«¯ API ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
  â†“
å‰ç«¯: æ¸…ç©º voiceCallMessages çŠ¶æ€
```

## ä»£ç æ¸…ç†æ¸…å•

### éœ€è¦åˆ é™¤çš„æ–‡ä»¶/ä»£ç 

1. âŒ `backend/app/api/v1/websocket.py` - åˆ é™¤æ•´ä¸ªæ–‡ä»¶ï¼ˆRealtime WebSocket è·¯ç”±ï¼‰
2. âŒ `backend/app/engines/voice/realtime/` - åˆ é™¤æ•´ä¸ªç›®å½•
   - `base.py`
   - `factory.py`
   - `openai_realtime.py`
   - `__init__.py`
3. âŒ `frontend/src/hooks/useRealtimeVoice.ts` - åˆ é™¤ï¼ˆæ›¿æ¢ä¸º useVoiceAgent.tsï¼‰

### éœ€è¦ä¿ç•™çš„æ–‡ä»¶

1. âœ… `backend/app/engines/voice/stt/` - STT å¼•æ“
2. âœ… `backend/app/engines/voice/tts/` - TTS å¼•æ“
3. âœ… `backend/app/api/v1/audio.py` - STT/TTS REST API
4. âœ… `backend/app/api/v1/chat.py` - LLM chat_completion API

### éœ€è¦æ–°å¢çš„æ–‡ä»¶

1. âœ… `backend/app/api/v1/config.py` - é…ç½®APIï¼ˆæä¾› OpenAI é…ç½®ï¼‰
2. âœ… `frontend/src/services/config.ts` - é…ç½®æœåŠ¡
3. âœ… `frontend/src/hooks/useVoiceAgent.ts` - Voice Agent Hook

### éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶

1. âœ… `frontend/src/features/chat/components/EnhancedChatContainer.tsx` - é›†æˆ useVoiceAgent
2. âœ… `frontend/src/store/slices/chatSlice.ts` - ä¿ç•™è¯­éŸ³é€šè¯çŠ¶æ€ï¼ˆå¦‚æœéœ€è¦ï¼‰
3. âœ… `backend/app/api/v1/__init__.py` - æ³¨å†Œæ–°çš„ config è·¯ç”±

## æ³¨æ„äº‹é¡¹

### 1. API Key å®‰å…¨

**é—®é¢˜**: å‰ç«¯ç›´æ¥ä½¿ç”¨ API key å­˜åœ¨æ³„éœ²é£é™©

**è§£å†³æ–¹æ¡ˆ**:
- âœ… ä½¿ç”¨ç”¨æˆ·è®¤è¯ï¼ˆJWT tokenï¼‰ä¿æŠ¤é…ç½®API
- âš ï¸ å¦‚æœæ‹…å¿ƒæ³„éœ²ï¼Œå¯ä»¥è€ƒè™‘ï¼š
  - ä½¿ç”¨ä¸´æ—¶ tokenï¼ˆçŸ­æœŸæœ‰æ•ˆï¼Œå¦‚1å°æ—¶ï¼‰
  - æˆ–è€…ä½¿ç”¨ CORS é™åˆ¶åŸŸå
  - æˆ–è€…ä½¿ç”¨åç«¯ä»£ç†ï¼ˆä½†ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºä¸æƒ³è¿™æ ·åšï¼‰

### 2. OpenAI Agents SDK ä½¿ç”¨

**æ–‡æ¡£å‚è€ƒ**:
- https://openai.github.io/openai-agents-js/guides/voice-agents/
- https://openai.github.io/openai-agents-js/guides/voice-agents/quickstart/
- https://openai.github.io/openai-agents-js/guides/voice-agents/build/
- https://openai.github.io/openai-agents-js/guides/voice-agents/transport/

**å…³é”®ç‚¹**:

1. **RealtimeAgent vs RealtimeSession**:
   - `RealtimeAgent`: å®šä¹‰ Agent çš„è¡Œä¸ºï¼ˆåç§°ã€æŒ‡ä»¤ã€å·¥å…·ç­‰ï¼‰
   - `RealtimeSession`: ç®¡ç†è¿æ¥å’ŒéŸ³é¢‘æµï¼ˆä¼ è¾“å±‚ï¼‰

2. **ä¼ è¾“å±‚é€‰æ‹©**:
   - **WebRTC**ï¼ˆæµè§ˆå™¨é»˜è®¤ï¼‰:
     - è‡ªåŠ¨å¤„ç†éŸ³é¢‘è¾“å…¥è¾“å‡º
     - æ— éœ€æ‰‹åŠ¨ç®¡ç†éŸ³é¢‘æµ
     - é€‚åˆæµè§ˆå™¨ç¯å¢ƒ
   - **WebSocket**ï¼ˆæœåŠ¡å™¨ç«¯ï¼‰:
     - éœ€è¦æ‰‹åŠ¨å¤„ç†éŸ³é¢‘æµ
     - é€‚åˆæœåŠ¡å™¨ç«¯åº”ç”¨

3. **äº‹ä»¶ç›‘å¬**:
   - `input_audio_transcription.done`: ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬å®Œæˆ
   - `response.text.done`: åŠ©æ‰‹æ–‡æœ¬å›å¤å®Œæˆ
   - `response.audio.delta`: åŠ©æ‰‹è¯­éŸ³æµï¼ˆå¢é‡ï¼‰
   - `error`: é”™è¯¯äº‹ä»¶

4. **éŸ³é¢‘å¤„ç†**:
   - WebRTC æ¨¡å¼ä¸‹ï¼ŒéŸ³é¢‘è‡ªåŠ¨å¤„ç†
   - æ— éœ€æ‰‹åŠ¨è°ƒç”¨ `sendAudio()` æˆ–å¤„ç†éŸ³é¢‘æ’­æ”¾
   - æµè§ˆå™¨ä¼šè‡ªåŠ¨è¯·æ±‚éº¦å…‹é£æƒé™

5. **CORS å¤„ç†**:
   - å¦‚æœ `base_url` ä¸æ˜¯ OpenAI å®˜æ–¹åŸŸåï¼Œéœ€è¦ç¡®ä¿ CORS é…ç½®æ­£ç¡®
   - å¯èƒ½éœ€è¦åç«¯ä»£ç†æˆ–é…ç½® CORS headers

### 3. æ¶ˆæ¯ä¿å­˜æ—¶æœº

- âœ… é€šè¯ç»“æŸæ—¶ç»Ÿä¸€ä¿å­˜æ‰€æœ‰æ¶ˆæ¯
- âœ… ä½¿ç”¨ç°æœ‰çš„ `POST /v1/chat/voice-call-messages` API

### 4. é”™è¯¯å¤„ç†

- âœ… WebSocket è¿æ¥å¤±è´¥
- âœ… å½•éŸ³æƒé™è¢«æ‹’ç»
- âœ… API key æ— æ•ˆ
- âœ… ç½‘ç»œé”™è¯¯

### 5. æ€§èƒ½ä¼˜åŒ–

- âœ… é¿å…é¢‘ç¹æ›´æ–° UI
- âœ… ä½¿ç”¨ React.memo ä¼˜åŒ–ç»„ä»¶
- âœ… éŸ³é¢‘æµå¤„ç†ä¼˜åŒ–

## å®æ–½æ­¥éª¤

1. **åç«¯**:
   - [ ] åˆ›å»º `backend/app/api/v1/config.py`
   - [ ] æ³¨å†Œé…ç½®è·¯ç”±
   - [ ] åˆ é™¤ `backend/app/api/v1/websocket.py`
   - [ ] åˆ é™¤ `backend/app/engines/voice/realtime/` ç›®å½•

2. **å‰ç«¯**:
   - [ ] å®‰è£… `@openai/agents` SDK
   - [ ] åˆ›å»º `frontend/src/services/config.ts`
   - [ ] åˆ›å»º `frontend/src/hooks/useVoiceAgent.ts`
   - [ ] ä¿®æ”¹ `EnhancedChatContainer.tsx` é›†æˆæ–° Hook
   - [ ] åˆ é™¤ `frontend/src/hooks/useRealtimeVoice.ts`

3. **æµ‹è¯•**:
   - [ ] æµ‹è¯•é…ç½®APIè·å–
   - [ ] æµ‹è¯• Voice Agent è¿æ¥
   - [ ] æµ‹è¯•è¯­éŸ³é€šè¯æµç¨‹
   - [ ] æµ‹è¯•æ¶ˆæ¯ä¿å­˜

## å…³é”®å®ç°ç»†èŠ‚

### RealtimeAgent é…ç½®

**Instructions è·å–ç­–ç•¥**:

```typescript
// ä» personality é…ç½®è·å– instructions
// ä¼˜å…ˆçº§ï¼švoice.realtime.instructions > ai.system_prompt > é»˜è®¤å€¼

// æ–¹å¼1ï¼šå¦‚æœ personality æ˜¯é€šè¿‡ API è·å–çš„å®Œæ•´é…ç½®å¯¹è±¡
const realtimeConfig = personality?.voice?.realtime || {};
const aiConfig = personality?.ai || {};

const instructions = realtimeConfig.instructions 
  || aiConfig.system_prompt 
  || 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€‚';

// æ–¹å¼2ï¼šå¦‚æœ personality æ˜¯é€šè¿‡ to_config() è¿”å›çš„å­—å…¸æ ¼å¼
const config = personality?.config || {};
const voiceConfig = config?.voice || {};
const realtimeConfig = voiceConfig?.realtime || {};
const aiConfig = config?.ai || {};

const instructions = realtimeConfig.instructions 
  || aiConfig.system_prompt 
  || 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€‚';

const agent = new RealtimeAgent({
  name: personality?.name || 'CozyChat Assistant',
  instructions: instructions,
  // å¯é€‰ï¼šå·¥å…·å®šä¹‰ï¼ˆå¯ä»¥ä» personality.tools è·å–ï¼‰
  tools: [],
  // å¯é€‰ï¼šæŠ¤æ ï¼ˆsafety guardrailsï¼‰
  guardrails: [],
});
```

**Instructions ä¼˜å…ˆçº§è¯´æ˜**:
1. **`voice.realtime.instructions`**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæ¨èï¼‰
   - ä¸“é—¨ä¸ºè¯­éŸ³å¯¹è¯è®¾è®¡çš„æç¤ºè¯
   - å¯ä»¥æ›´ç®€æ´ã€å£è¯­åŒ–
   - é€‚åˆè¯­éŸ³æ’­æ”¾çš„ç‰¹ç‚¹ï¼ˆå›å¤ç®€çŸ­ã€è‡ªç„¶ï¼‰
   - **å¯é€‰å­—æ®µ**ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å›é€€

2. **`ai.system_prompt`**ï¼ˆå›é€€é€‰é¡¹ï¼‰
   - æ™®é€šæ–‡æœ¬èŠå¤©çš„ç³»ç»Ÿæç¤ºè¯
   - å¦‚æœ `voice.realtime.instructions` ä¸å­˜åœ¨ï¼Œä½¿ç”¨å®ƒ
   - é€‚åˆæ–‡æœ¬å’Œè¯­éŸ³å…±ç”¨ç›¸åŒæç¤ºè¯çš„åœºæ™¯

3. **é»˜è®¤å€¼**ï¼ˆæœ€åå›é€€ï¼‰
   - å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯

### RealtimeSession é…ç½®

```typescript
const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2024-10-01',
  config: {
    // éŸ³é¢‘æ ¼å¼
    inputAudioFormat: 'pcm16',
    outputAudioFormat: 'pcm16',
    // è¾“å…¥éŸ³é¢‘è½¬å½•é…ç½®
    inputAudioTranscription: {
      model: 'whisper-1',
    },
    // è¯­éŸ³è®¾ç½®
    voice: 'shimmer', // å¯ä»¥ä» personality é…ç½®è·å–
    // å…¶ä»–é…ç½®...
  },
});
```

### äº‹ä»¶ç›‘å¬å®Œæ•´åˆ—è¡¨

```typescript
// ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆå¢é‡ï¼‰
session.on('input_audio_transcription.delta', (event) => {
  // event.delta: æ–‡æœ¬å¢é‡
});

// ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆå®Œæˆï¼‰
session.on('input_audio_transcription.done', (event) => {
  // event.transcript: å®Œæ•´æ–‡æœ¬
});

// åŠ©æ‰‹æ–‡æœ¬å›å¤ï¼ˆå¢é‡ï¼‰
session.on('response.text.delta', (event) => {
  // event.delta: æ–‡æœ¬å¢é‡
});

// åŠ©æ‰‹æ–‡æœ¬å›å¤ï¼ˆå®Œæˆï¼‰
session.on('response.text.done', (event) => {
  // event.text: å®Œæ•´æ–‡æœ¬
});

// åŠ©æ‰‹éŸ³é¢‘æµï¼ˆå¢é‡ï¼‰
session.on('response.audio.delta', (event) => {
  // event.delta: éŸ³é¢‘æ•°æ®ï¼ˆbase64ç¼–ç çš„PCM16ï¼‰
  // WebRTC æ¨¡å¼ä¸‹ä¼šè‡ªåŠ¨æ’­æ”¾ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†
});

// ä¼šè¯æ›´æ–°
session.on('session.update', (event) => {
  // ä¼šè¯é…ç½®æ›´æ–°
});

// é”™è¯¯äº‹ä»¶
session.on('error', (error) => {
  // å¤„ç†é”™è¯¯
});
```

### è¿æ¥å’Œç”Ÿå‘½å‘¨æœŸ

```typescript
// 1. è¿æ¥
await session.connect({
  apiKey: 'sk-xxx',
  baseURL: 'https://api.openai.com/v1',
});

// 2. å¼€å§‹ä¼šè¯ï¼ˆå¼€å§‹éŸ³é¢‘æµï¼‰
await session.start();

// 3. åœæ­¢ä¼šè¯ï¼ˆåœæ­¢éŸ³é¢‘æµï¼‰
await session.stop();

// 4. æ–­å¼€è¿æ¥
await session.disconnect();
```

### è‡ªå®šä¹‰ WebRTC ä¼ è¾“ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦è‡ªå®šä¹‰éŸ³é¢‘æµæˆ–éŸ³é¢‘å…ƒç´ ï¼š

```typescript
import { OpenAIRealtimeWebRTC } from '@openai/agents/realtime';

const mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
const audioElement = document.createElement('audio');
audioElement.autoplay = true;

const transport = new OpenAIRealtimeWebRTC({
  mediaStream,
  audioElement,
});

const session = new RealtimeSession(agent, {
  transport,
  model: 'gpt-4o-realtime-preview-2024-10-01',
});
```

## å‚è€ƒæ–‡æ¡£

- OpenAI Voice Agents æŒ‡å—: https://openai.github.io/openai-agents-js/guides/voice-agents/
- OpenAI Voice Agents å¿«é€Ÿå¼€å§‹: https://openai.github.io/openai-agents-js/guides/voice-agents/quickstart/
- OpenAI Voice Agents æ„å»ºæŒ‡å—: https://openai.github.io/openai-agents-js/guides/voice-agents/build/
- OpenAI Voice Agents ä¼ è¾“å±‚: https://openai.github.io/openai-agents-js/guides/voice-agents/transport/
- OpenAI Realtime API æ–‡æ¡£: https://platform.openai.com/docs/guides/voice-agents
- OpenAI Agents JS SDK: https://openai.github.io/openai-agents-js/
